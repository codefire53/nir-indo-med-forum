# Hybrid DPR-Sparse Retriever Model
This directory contains implementations for several DPR and sparse retriever model combinations. 

## Hybrid DPR-Sparse Retriever Model Alpha Variant
This model is implemented on rerank.py. To run this model, execute this command.
```
    python rerank.py --dpr_query_result <dpr-query-results-file> --bm25_query_result <bm25-query-results-file> --lmd_query_result <lmd-query-results-file> \\
    --classic_query_result <tfidf/classic-query-results-file> --pembeddings <passage-embeddings-file-generated-by-dpr> \\ 
    --qembeddings <query-embeddings-file-generated-by-dpr> --corpus <corpus-file> \\
    --top-k <top-k-passages-for-each-query> --eval_file <test query file which contains ground truth for each query> --fine_tune_data <training data name which is used to train dpr>
```

## Hybrid DPR-Sparse Retriever Model Alpha Beta Variant
This model is implemented on rerank_v2.py. To execute this model pretty much the same as the previous except we dont have to use --eval_file. This file depends on the alpha beta results from param-tuning-logistic.ipynb. That notebook contains the hyperparameter search process for each training data using logistic regression model.

## Retriever-Reranker Model
This model is implemented on rerank_sequential.py. If you want to run DPR retriever-sparse reranker, you can run this command.
```
    python rerank_sequential.py --dpr_retrieval_result <dpr query results file> --corpus <corpus file> --topk <top-k passages for each query> --sparse_tyoe <sparse model that we wanna use. example: BM25> --fine_tune_data <training data name that is used to train dpr>
```

For sparse retriever-DPR reranker, you can run this command.
```
    python rerank_sequential.py --sparse_retrieval_result <sparse query results file> --pembeddings <passage embeddings file generated by dpr> --qembeddings <query embeddings file produced by dpr> --sparse_type <sparse model name that is used for the retrieval> --fine_tune_data <training data name that is used to train dpr>
```